# cluster-sort
experiment using efficientnet and DBSCAN to sort images into groups like images scraped of the internet. Like differentiating between different kind bears and discarding irrelevant stuff that may end up in there such as things with bear in the name or the broken image icon.

The original idea was to probe the relationships between stuff using images. Lets say you were to grab a list of all nouns and set up code to download images of each. Then the images for each search can be cleaned and sorted into groups. This is pretty good at identifying duplicates so they can be removed and discarding irrelevant stuff such as the broken image icon that often end up in search results. What I still wanted to do is experiment with probing relationships between groups by comparing them. For example tyres should have some relationship to cars since cars have tyres but cars shouldn't really for tyres that much since tyres dont have cars and most pictures of tyres specifically is not of tyres on cars.

This code does seem to be biased to discarding images that is part of a group but rarely includes ones that is not. Another anoyance is the way that images are sorted into groups depends a lot on the amount of images and thier contents. This is probably a property of DBSCAN and an algorithm that create a tree structure of how images relate to each other with the relative distances between them might be more usefull. Still want to look into that. 
